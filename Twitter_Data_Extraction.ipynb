{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install twarc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install twarc tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from twarc import Twarc\n",
    "from pathlib import Path\n",
    "\n",
    "# Replace with your Twitter API credentials (Consumer Key, Consumer Secret, Access Token, Access Token Secret)\n",
    "consumer_key = \"XXX\"\n",
    "consumer_secret = \"XXX\"\n",
    "bearer_token = \"XXX\"\n",
    "access_token = \"XXX\"\n",
    "access_token_secret = \"XXX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from tqdm import tqdm\n",
    "from twarc import Twarc\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a Twarc instance with your credentials\n",
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "\n",
    "# Define the hashtag to search for\n",
    "hashtag = \"#ManipurViralVideo\"\n",
    "\n",
    "# Calculate the date 10 days ago from today (offset-naive datetime)\n",
    "end_date = datetime.now() - timedelta(days=1)\n",
    "start_date = end_date - timedelta(days=10)\n",
    "\n",
    "# Create a list to store tweets and their creation times\n",
    "tweets_data = []\n",
    "\n",
    "# Function to filter tweets with the specified hashtag and save them to the JSON file\n",
    "def search_and_save_tweets():\n",
    "    for tweet in tqdm(t.search(hashtag, lang=\"en\")):  # Filter for English tweets\n",
    "        tweet_date = datetime.strptime(tweet[\"created_at\"], \"%a %b %d %H:%M:%S %z %Y\")\n",
    "        tweet_date_naive = tweet_date.replace(tzinfo=None)  # Convert to offset-naive datetime\n",
    "        if start_date <= tweet_date_naive <= end_date:\n",
    "            tweets_data.append({\"tweet\": tweet[\"full_text\"], \"created_at\": tweet[\"created_at\"]})\n",
    "\n",
    "# Call the function to search and save English language tweets for the last 3 days\n",
    "search_and_save_tweets()\n",
    "\n",
    "# Create a DataFrame from the tweets data\n",
    "df = pd.DataFrame(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to an Excel file\n",
    "excel_output_file = Path(\"YOUR_PATH.xlsx\")\n",
    "df.to_excel(excel_output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
